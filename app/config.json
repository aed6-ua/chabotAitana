{
    "global": {
        "assistant": "GPTAssistant",
        "retriever": "LlamaindexRetriever",
        "embeddings": "LlamaindexEmbeddings",

        "log": "Y",
        "log_folder": "log/",
        "verbose": "Y"
    },
    
    "GPTAssistant": {
        "model_name": "gpt-3.5-turbo",
        "memory_context_size": 0,
        "temperature": 0.01,
        "max_tokens": 500
    },

    "LlamaindexAssistant": {
        "model_name": "gpt-3.5-turbo",
        "memory_context_size": 0,
        "temperature": 0.01,
        "max_tokens": 500
    },

    "LocalAssistant": {
        "serverURL": "172.25.2.137",
        "serverPort": 8000,
        "temperature": 0.01,
        "max_tokens": 500
    },
    
    "SentenceTransformerRetriever": {
        "model_name": "hackathon-pln-es/paraphrase-spanish-distilroberta",
        "num_chunks": 5,
        "chunk_size": 1000,
        "%_sim_relevance": 40,
        "number_of_documents": 5,

        "data_folder": "data/",
        "model_folder": "models/",
        "vector_folder": "storage/"
    },

    "LlamaindexRetriever": {
        "model_name": "hackathon-pln-es/paraphrase-spanish-distilroberta",
        "num_chunks": 5,
        "chunk_size": 1000,
        "%_sim_relevance": 40,
        "number_of_documents": 5,

        "data_folder": "data/",
        "model_folder": "models/",
        "vector_folder": "storage/"
    },

    "SentenceTransformerEmbeddings": {
        "model_name": "hackathon-pln-es/paraphrase-spanish-distilroberta",
        "data_folder": "data/",
        "model_folder": "models/",
        "vector_folder": "storage/",
        "chunk_size": 1000,
        "chunk_overlap": 32
    },

    "LlamaindexEmbeddings": {
        "model_name": "hackathon-pln-es/paraphrase-spanish-distilroberta",
        "data_folder": "data/",
        "model_folder": "models/",
        "vector_folder": "storage/",
        "chunk_size": 1000,
        "chunk_overlap": 32
    },

    "special_tokens": {
        "model": "<model>",
        "error": "<error>",
        "fall_back": "<fall_back>",
        "llm": "<llm>"
    }
}
  
